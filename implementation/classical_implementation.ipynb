{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python36964bit1fe2bb4cf81446c4930ef0f70b991c44",
   "display_name": "Python 3.6.9 64-bit"
  },
  "metadata": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# Classical Implementation\n",
    "In this notebook I have trained a classical (and likely biased) machine learning model on the original dataset"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## 1.1 Read in the data and export it as a CSV"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "with open('../german-credit-dataset/german.data-numeric', 'r') as infile:\n",
    "    data_contents = infile.read()    \n",
    "    data_contents = re.sub(r'[ ]+', \",\", data_contents)\n",
    "    data_contents = re.sub(r'^,', \"\", data_contents)\n",
    "    data_contents = re.sub(r'\\n,', \"\\n\", data_contents)\n",
    "    data_contents = re.sub(r',\\n', \"\\n\", data_contents)\n",
    "    # data_contents = re.sub(r'^,|\\n,|,\\n', \"\\n\", data_contents)\n",
    "\n",
    "    with open('../german-credit-dataset/german-numeric.csv', 'w') as outfile:\n",
    "        outfile.write(data_contents)"
   ]
  },
  {
   "source": [
    "## 1.2 Add column names to the data"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "data read in and column names applied\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# data = pd.read_csv('../german-credit-dataset/german.csv')\n",
    "data = pd.read_csv('../german-credit-dataset/german-numeric.csv', header=None)\n",
    "data.columns = [\n",
    "    'A1',\n",
    "    'A2',\n",
    "    'A3',\n",
    "    'A5*',\n",
    "    'A6',\n",
    "    'A7',\n",
    "    'A9',\n",
    "    'A11',\n",
    "    'A12',\n",
    "    'A13',\n",
    "    'A14',\n",
    "    'A16',\n",
    "    'A18',\n",
    "    'A19',\n",
    "    'A20',\n",
    "    'A4????',\n",
    "    'A8',\n",
    "    'A10a',\n",
    "    'A10b',\n",
    "    'A15a',\n",
    "    'A15b',\n",
    "    'A17a',\n",
    "    'A17b',\n",
    "    'A17c',\n",
    "    'Score'\n",
    "]\n",
    "\n",
    "\n",
    "print('data read in and column names applied')"
   ]
  },
  {
   "source": [
    "## 1.3 Encode the age data as Young (0) and Aged (1)"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.loc[data.A13 <= 25, \"A13\"] = 0\n",
    "data.loc[data.A13 > 25, \"A13\"] = 1"
   ]
  },
  {
   "source": [
    "## 1.4 Split the data into Features and labels and into training and testing"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "features = data.iloc[:, :24] # columns 0 to 19\n",
    "labels = data.iloc[:, 24] # column 20\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, labels, test_size=0.3, random_state=0) # This also shuffles the data\n"
   ]
  },
  {
   "source": [
    "## 2.1 Train a Naive Bayes model"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "GaussianNB(priors=None, var_smoothing=1e-09)"
      ]
     },
     "metadata": {},
     "execution_count": 62
    }
   ],
   "source": [
    "# Import and fit a naive bayes model\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "nb_classifier = GaussianNB()\n",
    "nb_classifier.fit(X_train, y_train)"
   ]
  },
  {
   "source": [
    "## 2.2 Evaluate the model"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_predictions = nb_classifier.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Accuracy of the Naive Bayes classifier 0.7266666666666667\n\nClassification report for Naive Bayes (0:died, 1:recovered):\n              precision    recall  f1-score   support\n\n        Good       0.85      0.75      0.80       214\n         Bad       0.52      0.67      0.59        86\n\n  \n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "\n",
    "print(f'Accuracy of the Naive Bayes classifier {metrics.accuracy_score(y_test, nb_predictions)}\\n')\n",
    "\n",
    "print(f'Classification report for Naive Bayes (0:died, 1:recovered):')\n",
    "print(metrics.classification_report(y_test, nb_predictions, target_names=['Good','Bad'])[:166])"
   ]
  },
  {
   "source": [
    "# Fairness adjustment"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## 1.1 Discrimination Measure\n",
    "We use the KCDM measure to test the Discrimination level present within the dataset."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "190\n110\n810\n590\n0.14944769330734242\n"
     ]
    }
   ],
   "source": [
    "young_group = data[data['A13'] == 0]\n",
    "young_group_good = young_group[young_group['Score'] == 1]\n",
    "aged_group = data[data['A13'] == 1]\n",
    "aged_group_good = aged_group[aged_group['Score'] == 1]\n",
    "\n",
    "print(young_group.shape[0])\n",
    "print(young_group_good.shape[0])\n",
    "print(aged_group.shape[0])\n",
    "print(aged_group_good.shape[0])\n",
    "\n",
    "discrimination = aged_group_good.shape[0] / aged_group.shape[0] - young_group_good.shape[0] / young_group.shape[0]\n",
    "print(discrimination)\n"
   ]
  },
  {
   "source": [
    "## Apply the CND algorithm"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "Next we use the naive bayes classifier to rank the instances by the probability of appearing in the positive class"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify the two groups, candidates for promotion and candidates for demotion\n",
    "# these will need identifying along with their index in the real dataset so that their labels can be flipped later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/home/sam/.local/lib/python3.6/site-packages/ipykernel_launcher.py:18: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    },
    {
     "output_type": "error",
     "ename": "ValueError",
     "evalue": "The truth value of a Series is ambiguous. Use a.empty, a.bool(), a.item(), a.any() or a.all().",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-83-98e9981d6e49>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'rank scores'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnb_predict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'expand'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m \u001b[0mcandidates_for_promotion\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mA13\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;36m0\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mY_train\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcandidates_for_promotion\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m__nonzero__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1328\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__nonzero__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1329\u001b[0m         raise ValueError(\n\u001b[0;32m-> 1330\u001b[0;31m             \u001b[0;34mf\"The truth value of a {type(self).__name__} is ambiguous. \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1331\u001b[0m             \u001b[0;34m\"Use a.empty, a.bool(), a.item(), a.any() or a.all().\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1332\u001b[0m         )\n",
      "\u001b[0;31mValueError\u001b[0m: The truth value of a Series is ambiguous. Use a.empty, a.bool(), a.item(), a.any() or a.all()."
     ]
    }
   ],
   "source": [
    "# Make another column and store the predicted score\n",
    "\n",
    "# print(nb_classifier.predict_proba(X_test.iloc[0:10]))\n",
    "# print(nb_classifier.predict(X_test.iloc[0:10]))\n",
    "\n",
    "def nb_predict(row):\n",
    "    '''\n",
    "    INPUT: A row from the feature data\n",
    "    RETURNS: The probability of that row belonging to the positive class\n",
    "    '''\n",
    "    a = row.values\n",
    "    a = a.reshape(1,-1)\n",
    "    ps = nb_classifier.predict_proba(a)\n",
    "    return ps[0][0]\n",
    "\n",
    "# print(rank(X_test.iloc[0]))\n",
    "\n",
    "X_train['rank scores'] = X_train.apply(nb_predict, axis=1, result_type='expand')\n",
    "\n",
    "candidates_for_promotion = X_train[X_train.A13==0 and Y_train == 2]\n",
    "print(candidates_for_promotion.shape)\n",
    "\n",
    "# Order the groups by the scores generated ae\n",
    "\n",
    "# Calculate how many swaps we need\n",
    "swaps_required = ( (young_group.shape[0] * aged_group_good.shape[0]) - (aged_group.shape[0] * young_group_good.shape[0]) ) / (young_group.shape[0] + aged_group.shape[0])\n",
    "\n",
    "# Make that many swaps\n",
    "for i in range(int(swaps_required)):\n",
    "    pass\n",
    "    # Swap the top object from CP\n",
    "    # Swap the top object from CD\n",
    "    # remove both from the lists\n"
   ]
  },
  {
   "source": [
    "# Evaluation and comparison"
   ],
   "cell_type": "markdown",
   "metadata": {}
  }
 ]
}