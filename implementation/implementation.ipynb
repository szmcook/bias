{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python36964bit1fe2bb4cf81446c4930ef0f70b991c44",
   "display_name": "Python 3.6.9 64-bit"
  },
  "metadata": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# Classical Implementation\n",
    "In this notebook I have trained a classical (and likely biased) machine learning model on the original dataset"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "Useful information for reference:\n",
    "\n",
    "number of instances: 1000 (190 young and 810 aged)\n",
    "\n",
    "labels: 1 is good, 2 is bad\n",
    "\n",
    "A13 == 0 means the individual is young"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## 0.1 Read in the data and export it as a CSV"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "with open('../german-credit-dataset/german.data-numeric', 'r') as infile:\n",
    "    data_contents = infile.read()    \n",
    "    data_contents = re.sub(r'[ ]+', \",\", data_contents)\n",
    "    data_contents = re.sub(r'^,', \"\", data_contents)\n",
    "    data_contents = re.sub(r'\\n,', \"\\n\", data_contents)\n",
    "    data_contents = re.sub(r',\\n', \"\\n\", data_contents)\n",
    "    # data_contents = re.sub(r'^,|\\n,|,\\n', \"\\n\", data_contents)\n",
    "\n",
    "    with open('../german-credit-dataset/german-numeric.csv', 'w') as outfile:\n",
    "        outfile.write(data_contents)"
   ]
  },
  {
   "source": [
    "## 0.2 Create a pandas dataframe holding the dataset\n",
    "\n",
    "The two most important data structures in this notebook are the original dataset, created below, and the modified dataset that's created in Task 4 (Fair implementation).\n",
    "\n",
    "The original dataset will be split into training and testing data, the training data will be used to create a modified (fair) dataset later whilst the testing data will not be used except for evaluating models trained on either the original training data or the fair training data."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "data read in and column names applied\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# data = pd.read_csv('../german-credit-dataset/german.csv')\n",
    "data = pd.read_csv('../german-credit-dataset/german-numeric.csv', header=None)\n",
    "data.columns = [\n",
    "    'A1',\n",
    "    'A2',\n",
    "    'A3',\n",
    "    'A5*',\n",
    "    'A6',\n",
    "    'A7',\n",
    "    'A9',\n",
    "    'A11',\n",
    "    'A12',\n",
    "    'A13',\n",
    "    'A14',\n",
    "    'A16',\n",
    "    'A18',\n",
    "    'A19',\n",
    "    'A20',\n",
    "    'A4????',\n",
    "    'A8',\n",
    "    'A10a',\n",
    "    'A10b',\n",
    "    'A15a',\n",
    "    'A15b',\n",
    "    'A17a',\n",
    "    'A17b',\n",
    "    'A17c',\n",
    "    'label'\n",
    "]\n",
    "\n",
    "\n",
    "print('data read in and column names applied')"
   ]
  },
  {
   "source": [
    "## 0.3 Encode the age data as Young (0) and Aged (1)"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.loc[data.A13 <= 25, \"A13\"] = 0\n",
    "data.loc[data.A13 > 25, \"A13\"] = 1"
   ]
  },
  {
   "source": [
    "## 3.3.2 Split the data into Features and labels and into training and testing"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "features = data.iloc[:, :24] # columns 0 to 24\n",
    "labels = data.iloc[:, 24] # column 25\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, labels, test_size=0.5, random_state=0) # This also shuffles the data\n",
    "\n",
    "# print(features.head)\n",
    "# print(labels.head)"
   ]
  },
  {
   "source": [
    "## 3.3.3a Train a Naive Bayes model"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "GaussianNB(priors=None, var_smoothing=1e-09)"
      ]
     },
     "metadata": {},
     "execution_count": 5
    }
   ],
   "source": [
    "# Import and fit a naive bayes model\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "nb_classifier = GaussianNB()\n",
    "nb_classifier.fit(X_train, y_train)"
   ]
  },
  {
   "source": [
    "## 3.3.3b Evaluate the model"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We also want to measure the disparate impact of a model\n",
    "def disparate_impact(trained_model, sensitive_value, sensitive_column, desired_label, X_test, y_test):\n",
    "    data_test = pd.concat([X_test, y_test], axis=1)\n",
    "\n",
    "    data_test_unprivileged = data_test[data_test[sensitive_column] == sensitive_value]\n",
    "    data_test_privileged = data_test[data_test[sensitive_column] != sensitive_value]\n",
    "\n",
    "    # measure the rate of good outcomes among the unprivileged applicants\n",
    "    X_test_up = data_test_unprivileged.iloc[:, :24] \n",
    "    predictions_up = trained_model.predict(X_test_up)\n",
    "    good_up = (predictions_up == 1).sum()/len(predictions_up)\n",
    "\n",
    "    X_test_p = data_test_privileged.iloc[:, :24] \n",
    "    predictions_p = trained_model.predict(X_test_p)\n",
    "    good_p = (predictions_p == 1).sum()/len(predictions_p)\n",
    "\n",
    "    return good_up/good_p\n",
    "    \n",
    "\n",
    "# disparate_impact(nb_classifier, 0, 'A13', 1, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "\n",
    "def evaluate(trained_model, X_test, y_test):\n",
    "    predictions = trained_model.predict(X_test)\n",
    "    print(f'Accuracy: {metrics.accuracy_score(y_test, predictions)}')\n",
    "    print(f'Disparate impact of classifier: {disparate_impact(trained_model, 0, \"A13\", 1, X_test, y_test)}')\n",
    "    print('Classification report:')\n",
    "    print(metrics.classification_report(y_test, predictions, target_names=['Good','Bad']))\n",
    "    print('Confusion matrix:')\n",
    "    print(metrics.confusion_matrix(y_test, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Accuracy: 0.686\nDisparate impact of classifier: 0.4015925480769231\nClassification report:\n              precision    recall  f1-score   support\n\n        Good       0.84      0.68      0.75       350\n         Bad       0.48      0.70      0.57       150\n\n   micro avg       0.69      0.69      0.69       500\n   macro avg       0.66      0.69      0.66       500\nweighted avg       0.73      0.69      0.70       500\n\nConfusion matrix:\n[[238 112]\n [ 45 105]]\n"
     ]
    }
   ],
   "source": [
    "evaluate(nb_classifier, X_test, y_test)"
   ]
  },
  {
   "source": [
    "## 3.3.4 Subsample a new dataset and retrain the model"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Accuracy: 0.675\nDisparate impact of classifier: 1.0368532955350815\nClassification report:\n              precision    recall  f1-score   support\n\n        Good       0.72      0.62      0.67        84\n         Bad       0.64      0.74      0.68        76\n\n   micro avg       0.68      0.68      0.68       160\n   macro avg       0.68      0.68      0.67       160\nweighted avg       0.68      0.68      0.67       160\n\nConfusion matrix:\n[[52 32]\n [20 56]]\n"
     ]
    }
   ],
   "source": [
    "# the aged group has 810 entries, 590 have the positive class\n",
    "# the young group has 190 entries, 110 have the positive class\n",
    "\n",
    "# sampled data should have 80 young +, young -, old +, old -?\n",
    "\n",
    "def resample(dataset):\n",
    "    young_group = dataset[dataset['A13'] == 0]\n",
    "\n",
    "    young_pos_group = young_group[young_group['label'] == 1]\n",
    "    young_pos_sample = young_pos_group.sample(n=80, random_state=0)\n",
    "\n",
    "    young_neg_group = young_group[young_group['label'] == 2]\n",
    "    young_neg_sample = young_neg_group.sample(n=80, random_state=0)\n",
    "\n",
    "    aged_group = dataset[dataset['A13'] == 1]\n",
    "\n",
    "    aged_pos_group = aged_group[aged_group['label'] == 1]\n",
    "    aged_pos_sample = aged_pos_group.sample(n=80, random_state=0)\n",
    "\n",
    "    aged_neg_group = aged_group[aged_group['label'] == 2]\n",
    "    aged_neg_sample = aged_neg_group.sample(n=80, random_state=0)\n",
    "\n",
    "    data_resampled = pd.concat([young_pos_sample, young_neg_sample, aged_pos_sample, aged_neg_sample])\n",
    "    return data_resampled\n",
    "\n",
    "# Resample the dataset\n",
    "data_resampled = resample(data)\n",
    "\n",
    "# Split the resampled dataset into training and testing data\n",
    "features_resampled = data_resampled.iloc[:, :24]\n",
    "labels_resampled = data_resampled.iloc[:, 24]\n",
    "X_train_resampled, X_test_resampled, y_train_resampled, y_test_resampled = train_test_split(features_resampled, labels_resampled, test_size=0.5, random_state=0) # This also shuffles the data\n",
    "\n",
    "# Train a Naive Bayes classifier on the resampled dataset\n",
    "nb_resampled = GaussianNB()\n",
    "nb_resampled.fit(X_train_resampled, y_train_resampled)\n",
    "evaluate(nb_resampled, X_test_resampled, y_test_resampled)\n",
    "\n",
    "# Measure the disparate impack of the classifier trained on the resampled dataset\n",
    "# disparate_impact(nb_resampled, 0, 'A13', 1, X_test_resampled, y_test_resampled)"
   ]
  },
  {
   "source": [
    "# Fairness adjustment"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## 3.4.0 Discrimination Measure\n",
    "We use the KCDM measure to test the Discrimination level present within the dataset."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "0.14944769330734242\n0.0\n"
     ]
    }
   ],
   "source": [
    "def test_discrimination(dataset, sensitive_value, sensitive_column, desired_class):\n",
    "    young_group = dataset[dataset[sensitive_column] == sensitive_value]\n",
    "    young_pos_group = young_group[young_group['label'] == desired_class]\n",
    "    aged_group = dataset[dataset[sensitive_column] != sensitive_value]\n",
    "    aged_pos_group = aged_group[aged_group['label'] == desired_class]\n",
    "\n",
    "    # print(young_group.shape[0])\n",
    "    # print(young_pos_group.shape[0])\n",
    "    # print(aged_group.shape[0])\n",
    "    # print(aged_pos_group.shape[0])\n",
    "\n",
    "    discrimination = aged_pos_group.shape[0] / aged_group.shape[0] - young_pos_group.shape[0] / young_group.shape[0]\n",
    "    return discrimination\n",
    "\n",
    "print(test_discrimination(data, 0, 'A13', 1))\n",
    "print(test_discrimination(data_resampled, 0, 'A13', 1))\n"
   ]
  },
  {
   "source": [
    "## Apply the CND algorithm"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "The first step is to create a new dataset which is a concatenation of X_train and y_train, this will be modified to become unbiased"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.12919896640826867"
      ]
     },
     "metadata": {},
     "execution_count": 11
    }
   ],
   "source": [
    "training_data = pd.concat((X_train, y_train), axis=1)\n",
    "\n",
    "test_discrimination(training_data, 0, 'A13', 1)\n",
    "\n",
    "# print(new_dataset)\n",
    "\n",
    "# a = new_dataset[new_dataset['label'] == 1]\n",
    "# b = new_dataset[new_dataset['A13'] == 1]\n",
    "# c = a[a['A13'] == 1]\n",
    "\n",
    "# a.shape, b.shape, c.shape"
   ]
  },
  {
   "source": [
    "We want to add a list of label probabilities to this using the pre-built classifier"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rank(dataset, sensitive_value, sensitive_column, desired_label):\n",
    "    # Train a classifier using all the data available\n",
    "    features = dataset.iloc[:, :24] # columns 0 to 24\n",
    "    labels = dataset.iloc[:, 24] # column 25\n",
    "\n",
    "    nb_classifier2 = GaussianNB()\n",
    "    nb_classifier2.fit(features, labels)\n",
    "\n",
    "    def nb_predict(row):\n",
    "        '''\n",
    "        INPUT: A row from the feature data\n",
    "        RETURNS: The probability of that row belonging to the positive class\n",
    "        '''\n",
    "        a = row.values\n",
    "        a = a.reshape(1,-1)\n",
    "        ps = nb_classifier2.predict_proba(a)\n",
    "        return ps[0][0]\n",
    "\n",
    "    # Calculate the probabilities R[x] for x in D and store them in a new column\n",
    "    dataset['rank_score'] = features.apply(nb_predict, axis=1, result_type='expand')\n",
    "    dataset['label'] = labels\n",
    "\n",
    "    # We also add indices for reference\n",
    "    # dataset['new_index'] = range(len(dataset))\n",
    "\n",
    "    candidates_for_promotion = dataset[dataset[sensitive_column] == sensitive_value][dataset['label'] != desired_label]\n",
    "    # print(candidates_for_promotion.shape)\n",
    "    candidates_for_promotion.sort_values('rank_score', inplace=True, ascending=False)\n",
    "    \n",
    "    candidates_for_demotion = dataset[dataset[sensitive_column] != sensitive_value][dataset['label'] == desired_label]\n",
    "    # print(candidates_for_demotion.shape)\n",
    "    candidates_for_demotion.sort_values('rank_score', inplace=True, ascending=True)\n",
    "\n",
    "    rest_of_dataset_1 = dataset[dataset[sensitive_column] == sensitive_value][dataset['label'] == desired_label]\n",
    "    rest_of_dataset_2 = dataset[dataset[sensitive_column] != sensitive_value][dataset['label'] != desired_label]\n",
    "    rest_of_dataset = pd.concat([rest_of_dataset_1, rest_of_dataset_2])\n",
    "\n",
    "    return candidates_for_promotion, candidates_for_demotion, rest_of_dataset\n",
    "\n",
    "# rank(new_dataset, 0, 'A13', 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/home/sam/.local/lib/python3.6/site-packages/ipykernel_launcher.py:25: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "/home/sam/.local/lib/python3.6/site-packages/ipykernel_launcher.py:29: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "/home/sam/.local/lib/python3.6/site-packages/ipykernel_launcher.py:33: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "/home/sam/.local/lib/python3.6/site-packages/ipykernel_launcher.py:34: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "/home/sam/.local/lib/python3.6/site-packages/ipykernel_launcher.py:20: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/home/sam/.local/lib/python3.6/site-packages/ipykernel_launcher.py:24: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "9 swaps were required to reduce the bias in the dataset\n"
     ]
    }
   ],
   "source": [
    "def cnd(dataset, sensitive_value, sensitive_column, desired_label):\n",
    "\n",
    "    candidates_for_promotion, candidates_for_demotion, rest_of_dataset = rank(dataset, sensitive_value, sensitive_column, desired_label)\n",
    "    \n",
    "    # Calculate how many swaps we need\n",
    "    young_group = dataset[dataset[sensitive_column] == sensitive_value]\n",
    "    s = len(young_group)\n",
    "    young_pos_group = young_group[young_group['label'] == desired_label]\n",
    "    s_pos = len(young_pos_group)\n",
    "\n",
    "    aged_group = dataset[dataset[sensitive_column] != sensitive_value]\n",
    "    s_hat = len(aged_group)\n",
    "    aged_pos_group = aged_group[aged_group['label'] == desired_label]\n",
    "    s_hat_pos = len(aged_pos_group)\n",
    "    swaps_required = round(( (s * s_hat_pos) - (s_hat * s_pos) ) / (s + s_hat))\n",
    "    # print(swaps_required)\n",
    "\n",
    "    for i in range(int(swaps_required)):\n",
    "        row_cp = candidates_for_promotion.iloc[[i]]\n",
    "        row_cp['label'] = 1\n",
    "        candidates_for_promotion.iloc[[i]] = row_cp\n",
    "\n",
    "        row_cd = candidates_for_demotion.iloc[[i]]\n",
    "        row_cd['label'] = 2\n",
    "        candidates_for_demotion.iloc[[i]] = row_cd\n",
    "\n",
    "    print(f'{swaps_required} swaps were required to reduce the bias in the dataset')\n",
    "\n",
    "    \n",
    "    new_dataset = pd.concat([rest_of_dataset, candidates_for_promotion, candidates_for_demotion])\n",
    "    return new_dataset\n",
    "\n",
    "data_cnd = cnd(training_data, 0, 'A13', 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "0.002808673182788435\n"
     ]
    }
   ],
   "source": [
    "X_train_cnd = data_cnd.iloc[:, :24] # columns 0 to 24\n",
    "Y_train_cnd = data_cnd.iloc[:, 24] # column 25\n",
    "\n",
    "print(test_discrimination(data_cnd, 0, 'A13', 1))"
   ]
  },
  {
   "source": [
    "Train a new, unbiased model"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "GaussianNB(priors=None, var_smoothing=1e-09)"
      ]
     },
     "metadata": {},
     "execution_count": 15
    }
   ],
   "source": [
    "nb_cnd = GaussianNB()\n",
    "nb_cnd.fit(X_train_cnd, Y_train_cnd)"
   ]
  },
  {
   "source": [
    "# Evaluation and comparison"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Evaluating the original (biased) classifier:\nAccuracy: 0.686\nDisparate impact of classifier: 0.4015925480769231\nClassification report:\n              precision    recall  f1-score   support\n\n        Good       0.84      0.68      0.75       350\n         Bad       0.48      0.70      0.57       150\n\n   micro avg       0.69      0.69      0.69       500\n   macro avg       0.66      0.69      0.66       500\nweighted avg       0.73      0.69      0.70       500\n\nConfusion matrix:\n[[238 112]\n [ 45 105]]\n\n\nEvaluating the CND-trained classifier:\nAccuracy: 0.69\nDisparate impact of classifier: 0.7761834319526627\nClassification report:\n              precision    recall  f1-score   support\n\n        Good       0.81      0.73      0.77       350\n         Bad       0.49      0.61      0.54       150\n\n   micro avg       0.69      0.69      0.69       500\n   macro avg       0.65      0.67      0.65       500\nweighted avg       0.71      0.69      0.70       500\n\nConfusion matrix:\n[[254  96]\n [ 59  91]]\n"
     ]
    }
   ],
   "source": [
    "print('Evaluating the original (biased) classifier:')\n",
    "evaluate(nb_classifier, X_test, y_test)\n",
    "\n",
    "print('\\n\\nEvaluating the CND-trained classifier:')\n",
    "evaluate(nb_cnd, X_test, y_test)"
   ]
  }
 ]
}