{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python36964bit1fe2bb4cf81446c4930ef0f70b991c44",
   "display_name": "Python 3.6.9 64-bit"
  },
  "metadata": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# 2 Analysis"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "with open('../german-credit-dataset/german.data', 'r') as infile:\n",
    "    data_contents = infile.read()    \n",
    "    data_contents = re.sub(r' ', \",\", data_contents)\n",
    "\n",
    "    with open('../german-credit-dataset/german.csv', 'w') as outfile:\n",
    "        outfile.write(data_contents)\n",
    "\n",
    "data = pd.read_csv('../german-credit-dataset/german.csv')\n",
    "\n",
    "data.columns = [\n",
    "    'Status of existing checking account', \n",
    "    'Duration in month',\n",
    "    'Credit history',\n",
    "    'Purpose',\n",
    "    'Credit amount',\n",
    "    'Savings account/bonds',\n",
    "    'Present employment since',\n",
    "    'Installment rate in percentage of disposable income',\n",
    "    'Personal status and sex',\n",
    "    'Other debtors / guarantors',\n",
    "    'Present residence since',\n",
    "    'Property',\n",
    "    'Age in years',\n",
    "    'Other installment plans',\n",
    "    'Housing',\n",
    "    'Number of existing credits at this bank',\n",
    "    'Job',\n",
    "    'Number of people being liable to provide maintenance for',\n",
    "    'Telephone',\n",
    "    'foreign worker',\n",
    "    'label']\n",
    "\n",
    "numeric_columns = ['Duration in month', 'Credit amount', 'Installment rate in percentage of disposable income', 'Present residence since', 'Age in years', 'Number of existing credits at this bank', 'Number of people being liable to provide maintenance for']\n",
    "\n",
    "young_group = data[data['Age in years'] <= 25]\n",
    "aged_group = data[data['Age in years'] > 25]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Printing the young group value counts for each column\nA11    68\nA12    62\nA14    50\nA13    10\nName: Status of existing checking account, dtype: int64\nA32    137\nA34     33\nA31      8\nA33      7\nA30      5\nName: Credit history, dtype: int64\nA43    64\nA42    52\nA40    32\nA41    14\nA49    10\nA46     7\nA45     6\nA44     4\nA48     1\nName: Purpose, dtype: int64\nA61    123\nA65     28\nA62     22\nA63     11\nA64      6\nName: Savings account/bonds, dtype: int64\nA73    78\nA72    54\nA74    36\nA75    13\nA71     9\nName: Present employment since, dtype: int64\nA92    105\nA93     56\nA94     27\nA91      2\nName: Personal status and sex, dtype: int64\nA101    170\nA103     11\nA102      9\nName: Other debtors / guarantors, dtype: int64\nA123    71\nA121    60\nA122    47\nA124    12\nName: Property, dtype: int64\nA143    161\nA141     20\nA142      9\nName: Other installment plans, dtype: int64\nA152    106\nA151     79\nA153      5\nName: Housing, dtype: int64\nA173    138\nA172     42\nA171      5\nA174      5\nName: Job, dtype: int64\nA191    145\nA192     45\nName: Telephone, dtype: int64\nA201    187\nA202      3\nName: foreign worker, dtype: int64\n1    110\n2     80\nName: label, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print('Printing the young group value counts for each column')\n",
    "for c in data.columns:\n",
    "    if c not in numeric_columns:\n",
    "        print(young_group[c].value_counts())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Printing the aged group value counts for each column\nA14    344\nA12    207\nA11    205\nA13     53\nName: Status of existing checking account, dtype: int64\nA32    393\nA34    259\nA33     81\nA31     41\nA30     35\nName: Credit history, dtype: int64\nA43     215\nA40     202\nA42     129\nA41      89\nA49      87\nA46      43\nA45      16\nA410     12\nA48       8\nA44       8\nName: Purpose, dtype: int64\nA61    480\nA65    154\nA62     81\nA63     52\nA64     42\nName: Savings account/bonds, dtype: int64\nA73    261\nA75    239\nA74    138\nA72    118\nA71     53\nName: Present employment since, dtype: int64\nA93    491\nA92    205\nA94     65\nA91     48\nName: Personal status and sex, dtype: int64\nA101    736\nA103     41\nA102     32\nName: Other debtors / guarantors, dtype: int64\nA123    261\nA121    221\nA122    185\nA124    142\nName: Property, dtype: int64\nA143    652\nA141    119\nA142     38\nName: Other installment plans, dtype: int64\nA152    606\nA153    103\nA151    100\nName: Housing, dtype: int64\nA173    491\nA172    158\nA174    143\nA171     17\nName: Job, dtype: int64\nA191    451\nA192    358\nName: Telephone, dtype: int64\nA201    775\nA202     34\nName: foreign worker, dtype: int64\n1    589\n2    220\nName: label, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print('Printing the aged group value counts for each column')\n",
    "for c in data.columns:\n",
    "    if c not in numeric_columns:\n",
    "        print(aged_group[c].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Duration in month\nmean: 20.705263157894738\nvariance 149.4682261208577\n\nCredit amount\nmean: 3003.357894736842\nvariance 7967121.14107491\n\nInstallment rate in percentage of disposable income\nmean: 2.831578947368421\nvariance 1.3577276524644946\n\nPresent residence since\nmean: 2.8157894736842106\nvariance 1.3574213311055414\n\nAge in years\nmean: 23.110526315789475\nvariance 2.3633806739069896\n\nNumber of existing credits at this bank\nmean: 1.2421052631578948\nvariance 0.19504316346421613\n\nNumber of people being liable to provide maintenance for\nmean: 1.0315789473684212\nvariance 0.030743525480367587\n\n"
     ]
    }
   ],
   "source": [
    "for col in numeric_columns:\n",
    "    print(col)\n",
    "    print('mean:', young_group[col].mean())\n",
    "    print('variance', young_group[col].var())\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Duration in month\n",
      "mean: 20.96786155747837\n",
      "variance 144.53856980259212\n",
      "\n",
      "Credit amount\n",
      "mean: 3336.7750309023486\n",
      "variance 7961090.639920327\n",
      "\n",
      "Installment rate in percentage of disposable income\n",
      "mean: 3.004944375772559\n",
      "variance 1.2227478001199379\n",
      "\n",
      "Present residence since\n",
      "mean: 2.850432632880099\n",
      "variance 1.186760332399124\n",
      "\n",
      "Age in years\n",
      "mean: 38.427688504326326\n",
      "variance 113.53467794245432\n",
      "\n",
      "Number of existing credits at this bank\n",
      "mean: 1.4449938195302843\n",
      "variance 0.35866612001125947\n",
      "\n",
      "Number of people being liable to provide maintenance for\n",
      "mean: 1.1841779975278122\n",
      "variance 0.1504424237232129\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for col in numeric_columns:\n",
    "    print(col)\n",
    "    print('mean:', aged_group[col].mean())\n",
    "    print('variance', aged_group[col].var())\n",
    "    print()"
   ]
  },
  {
   "source": [
    "# 3 Implementation\n",
    "The implementation section this notebook is divided into 3 separate sections\n",
    "- Sections 0.x refer to the reading in and tidying up of the dataset\n",
    "- Sections 3.3.x refer to the implementation of a classical (and likely biased) machine learning model using the original dataset\n",
    "- Sections 3.4.x refer to the implementation of my chosen technique to reduce bias"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "Useful information for reference:\n",
    "\n",
    "number of instances: 1000 (190 young and 810 aged)\n",
    "\n",
    "labels: 1 is good, 2 is bad\n",
    "\n",
    "A13 == 0 means the individual is young"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## 0.1 Read in the data and export it as a CSV"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "with open('../german-credit-dataset/german.data-numeric', 'r') as infile:\n",
    "    data_contents = infile.read()    \n",
    "    data_contents = re.sub(r'[ ]+', \",\", data_contents)\n",
    "    data_contents = re.sub(r'^,', \"\", data_contents)\n",
    "    data_contents = re.sub(r'\\n,', \"\\n\", data_contents)\n",
    "    data_contents = re.sub(r',\\n', \"\\n\", data_contents)\n",
    "    # data_contents = re.sub(r'^,|\\n,|,\\n', \"\\n\", data_contents)\n",
    "\n",
    "    with open('../german-credit-dataset/german-numeric.csv', 'w') as outfile:\n",
    "        outfile.write(data_contents)"
   ]
  },
  {
   "source": [
    "## 0.2 Create a pandas dataframe holding the dataset\n",
    "\n",
    "The two most important data structures in this notebook are the original dataset, created below, and the modified dataset that's created in Task 4 (Fair implementation).\n",
    "\n",
    "The original dataset will be split into training and testing data, the training data will be used to create a modified (fair) dataset later whilst the testing data will not be used except for evaluating models trained on either the original training data or the fair training data."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "data read in and column names applied\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# data = pd.read_csv('../german-credit-dataset/german.csv')\n",
    "data = pd.read_csv('../german-credit-dataset/german-numeric.csv', header=None)\n",
    "data.columns = [\n",
    "    'A1',\n",
    "    'A2',\n",
    "    'A3',\n",
    "    'A5*',\n",
    "    'A6',\n",
    "    'A7',\n",
    "    'A9',\n",
    "    'A11',\n",
    "    'A12',\n",
    "    'A13',\n",
    "    'A14',\n",
    "    'A16',\n",
    "    'A18',\n",
    "    'A19',\n",
    "    'A20',\n",
    "    'A4????',\n",
    "    'A8',\n",
    "    'A10a',\n",
    "    'A10b',\n",
    "    'A15a',\n",
    "    'A15b',\n",
    "    'A17a',\n",
    "    'A17b',\n",
    "    'A17c',\n",
    "    'label'\n",
    "]\n",
    "\n",
    "\n",
    "print('data read in and column names applied')"
   ]
  },
  {
   "source": [
    "## 0.3 Encode the age data as Young (0) and Aged (1)"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.loc[data.A13 <= 25, \"A13\"] = 0\n",
    "data.loc[data.A13 > 25, \"A13\"] = 1"
   ]
  },
  {
   "source": [
    "## 3.3.2 Split the data into Features and labels and into training and testing"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "features = data.iloc[:, :24] # columns 0 to 24\n",
    "labels = data.iloc[:, 24] # column 25\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, labels, test_size=0.5, random_state=0) # This also shuffles the data\n",
    "\n",
    "# print(features.head)\n",
    "# print(labels.head)"
   ]
  },
  {
   "source": [
    "## 3.3.3a Train a Naive Bayes model\n",
    "Here I train the classicla Naive Bayes model using the original dataset."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "GaussianNB(priors=None, var_smoothing=1e-09)"
      ]
     },
     "metadata": {},
     "execution_count": 10
    }
   ],
   "source": [
    "# Import and fit a naive bayes model\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "nb_classifier = GaussianNB()\n",
    "nb_classifier.fit(X_train, y_train)"
   ]
  },
  {
   "source": [
    "## 3.3.3b Evaluate the model\n",
    "To evaluate this model I want to consider the accuracy of its predictions and the score it receives for disparate impact.\n",
    "I also chose to print out the confusion matrix and classification report."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We also want to measure the disparate impact of a model\n",
    "def disparate_impact(trained_model, sensitive_value, sensitive_column, desired_label, X_test, y_test):\n",
    "    data_test = pd.concat([X_test, y_test], axis=1)\n",
    "\n",
    "    data_test_unprivileged = data_test[data_test[sensitive_column] == sensitive_value]\n",
    "    data_test_privileged = data_test[data_test[sensitive_column] != sensitive_value]\n",
    "\n",
    "    # measure the rate of good outcomes among the unprivileged applicants\n",
    "    X_test_up = data_test_unprivileged.iloc[:, :24] \n",
    "    predictions_up = trained_model.predict(X_test_up)\n",
    "    good_up = (predictions_up == 1).sum()/len(predictions_up)\n",
    "\n",
    "    X_test_p = data_test_privileged.iloc[:, :24] \n",
    "    predictions_p = trained_model.predict(X_test_p)\n",
    "    good_p = (predictions_p == 1).sum()/len(predictions_p)\n",
    "\n",
    "    return good_up/good_p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "\n",
    "def evaluate(trained_model, X_test, y_test):\n",
    "    predictions = trained_model.predict(X_test)\n",
    "    print(f'Accuracy: {metrics.accuracy_score(y_test, predictions)}')\n",
    "    print(f'Disparate impact of classifier: {disparate_impact(trained_model, 0, \"A13\", 1, X_test, y_test)}')\n",
    "    print('Classification report:')\n",
    "    print(metrics.classification_report(y_test, predictions, target_names=['Good','Bad']))\n",
    "    print('Confusion matrix:')\n",
    "    print(metrics.confusion_matrix(y_test, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Accuracy: 0.686\nDisparate impact of classifier: 0.4015925480769231\nClassification report:\n              precision    recall  f1-score   support\n\n        Good       0.84      0.68      0.75       350\n         Bad       0.48      0.70      0.57       150\n\n   micro avg       0.69      0.69      0.69       500\n   macro avg       0.66      0.69      0.66       500\nweighted avg       0.73      0.69      0.70       500\n\nConfusion matrix:\n[[238 112]\n [ 45 105]]\n"
     ]
    }
   ],
   "source": [
    "evaluate(nb_classifier, X_test, y_test)"
   ]
  },
  {
   "source": [
    "## 3.3.4 Subsample a new dataset and retrain the model"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Accuracy: 0.675\nDisparate impact of classifier: 1.0368532955350815\nClassification report:\n              precision    recall  f1-score   support\n\n        Good       0.72      0.62      0.67        84\n         Bad       0.64      0.74      0.68        76\n\n   micro avg       0.68      0.68      0.68       160\n   macro avg       0.68      0.68      0.67       160\nweighted avg       0.68      0.68      0.67       160\n\nConfusion matrix:\n[[52 32]\n [20 56]]\n"
     ]
    }
   ],
   "source": [
    "# the aged group has 810 entries, 590 have the positive class\n",
    "# the young group has 190 entries, 110 have the positive class\n",
    "\n",
    "# sampled data should have 80 young +, young -, old +, old -?\n",
    "\n",
    "def resample(dataset):\n",
    "    young_group = dataset[dataset['A13'] == 0]\n",
    "\n",
    "    young_pos_group = young_group[young_group['label'] == 1]\n",
    "    young_pos_sample = young_pos_group.sample(n=80, random_state=0)\n",
    "\n",
    "    young_neg_group = young_group[young_group['label'] == 2]\n",
    "    young_neg_sample = young_neg_group.sample(n=80, random_state=0)\n",
    "\n",
    "    aged_group = dataset[dataset['A13'] == 1]\n",
    "\n",
    "    aged_pos_group = aged_group[aged_group['label'] == 1]\n",
    "    aged_pos_sample = aged_pos_group.sample(n=80, random_state=0)\n",
    "\n",
    "    aged_neg_group = aged_group[aged_group['label'] == 2]\n",
    "    aged_neg_sample = aged_neg_group.sample(n=80, random_state=0)\n",
    "\n",
    "    data_resampled = pd.concat([young_pos_sample, young_neg_sample, aged_pos_sample, aged_neg_sample])\n",
    "    return data_resampled\n",
    "\n",
    "# Resample the dataset\n",
    "data_resampled = resample(data)\n",
    "\n",
    "# Split the resampled dataset into training and testing data\n",
    "features_resampled = data_resampled.iloc[:, :24]\n",
    "labels_resampled = data_resampled.iloc[:, 24]\n",
    "X_train_resampled, X_test_resampled, y_train_resampled, y_test_resampled = train_test_split(features_resampled, labels_resampled, test_size=0.5, random_state=0) # This also shuffles the data\n",
    "\n",
    "# Train a Naive Bayes classifier on the resampled dataset\n",
    "nb_resampled = GaussianNB()\n",
    "nb_resampled.fit(X_train_resampled, y_train_resampled)\n",
    "evaluate(nb_resampled, X_test_resampled, y_test_resampled)\n",
    "\n",
    "# Measure the disparate impack of the classifier trained on the resampled dataset\n",
    "# disparate_impact(nb_resampled, 0, 'A13', 1, X_test_resampled, y_test_resampled)"
   ]
  },
  {
   "source": [
    "# Fairness adjustment"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## 3.4.0 Discrimination Measure\n",
    "We use the KCDM measure to test the Discrimination level present within the dataset."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "0.14944769330734242\n0.0\n"
     ]
    }
   ],
   "source": [
    "def test_discrimination(dataset, sensitive_value, sensitive_column, desired_class):\n",
    "    young_group = dataset[dataset[sensitive_column] == sensitive_value]\n",
    "    young_pos_group = young_group[young_group['label'] == desired_class]\n",
    "    aged_group = dataset[dataset[sensitive_column] != sensitive_value]\n",
    "    aged_pos_group = aged_group[aged_group['label'] == desired_class]\n",
    "\n",
    "    # print(young_group.shape[0])\n",
    "    # print(young_pos_group.shape[0])\n",
    "    # print(aged_group.shape[0])\n",
    "    # print(aged_pos_group.shape[0])\n",
    "\n",
    "    discrimination = aged_pos_group.shape[0] / aged_group.shape[0] - young_pos_group.shape[0] / young_group.shape[0]\n",
    "    return discrimination\n",
    "\n",
    "print(test_discrimination(data, 0, 'A13', 1))\n",
    "print(test_discrimination(data_resampled, 0, 'A13', 1))\n"
   ]
  },
  {
   "source": [
    "## 3.4.1 Apply the CND algorithm\n",
    "In this section I apply the CND algorithm to the training data from above. This yields an unbiased classifier which is then evaluated and compared with the original classifier."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "The first step is to combine X_train and y_train, this is the dataset which I will modify to become unbiased.\n",
    "I also test its level of discrimination using the function defined above."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.12919896640826867"
      ]
     },
     "metadata": {},
     "execution_count": 16
    }
   ],
   "source": [
    "training_data = pd.concat((X_train, y_train), axis=1)\n",
    "# print(new_dataset.head)\n",
    "\n",
    "test_discrimination(training_data, 0, 'A13', 1)"
   ]
  },
  {
   "source": [
    "I use the rank() function to return a set of candidates for promotion, a set of candidates for demotion and the rest of the dataset (which should remain untouched)"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rank(dataset, sensitive_value, sensitive_column, desired_label):\n",
    "    # Train a classifier using all the data available\n",
    "    features = dataset.iloc[:, :24] # columns 0 to 24\n",
    "    labels = dataset.iloc[:, 24] # column 25\n",
    "\n",
    "    nb_classifier2 = GaussianNB()\n",
    "    nb_classifier2.fit(features, labels)\n",
    "\n",
    "    def nb_predict(row):\n",
    "        '''\n",
    "        INPUT: A row from the feature data\n",
    "        RETURNS: The probability of that row belonging to the positive class\n",
    "        '''\n",
    "        a = row.values\n",
    "        a = a.reshape(1,-1)\n",
    "        ps = nb_classifier2.predict_proba(a)\n",
    "        return ps[0][0]\n",
    "\n",
    "    # Calculate the probabilities R[x] for x in D and store them in a new column\n",
    "    dataset['rank_score'] = features.apply(nb_predict, axis=1, result_type='expand')\n",
    "    dataset['label'] = labels\n",
    "\n",
    "    candidates_for_promotion = dataset[dataset[sensitive_column] == sensitive_value][dataset['label'] != desired_label]\n",
    "    # print(candidates_for_promotion.shape)\n",
    "    candidates_for_promotion.sort_values('rank_score', inplace=True, ascending=False)\n",
    "    \n",
    "    candidates_for_demotion = dataset[dataset[sensitive_column] != sensitive_value][dataset['label'] == desired_label]\n",
    "    # print(candidates_for_demotion.shape)\n",
    "    candidates_for_demotion.sort_values('rank_score', inplace=True, ascending=True)\n",
    "\n",
    "    rest_of_dataset_1 = dataset[dataset[sensitive_column] == sensitive_value][dataset['label'] == desired_label]\n",
    "    rest_of_dataset_2 = dataset[dataset[sensitive_column] != sensitive_value][dataset['label'] != desired_label]\n",
    "    rest_of_dataset = pd.concat([rest_of_dataset_1, rest_of_dataset_2])\n",
    "\n",
    "    return candidates_for_promotion, candidates_for_demotion, rest_of_dataset"
   ]
  },
  {
   "source": [
    "Here I implement the CND algorithm which takes a dataset and the relevant information and returns a dataset with KCDM=0."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/home/sam/.local/lib/python3.6/site-packages/ipykernel_launcher.py:23: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n/home/sam/.local/lib/python3.6/site-packages/ipykernel_launcher.py:27: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n/home/sam/.local/lib/python3.6/site-packages/ipykernel_launcher.py:31: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n/home/sam/.local/lib/python3.6/site-packages/ipykernel_launcher.py:32: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n/home/sam/.local/lib/python3.6/site-packages/ipykernel_launcher.py:19: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n/home/sam/.local/lib/python3.6/site-packages/ipykernel_launcher.py:23: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    }
   ],
   "source": [
    "def CND(dataset, sensitive_value, sensitive_column, desired_label):\n",
    "\n",
    "    candidates_for_promotion, candidates_for_demotion, rest_of_dataset = rank(dataset, sensitive_value, sensitive_column, desired_label)\n",
    "    \n",
    "    # Calculate how many swaps we need\n",
    "    young_group = dataset[dataset[sensitive_column] == sensitive_value]\n",
    "    s = len(young_group)\n",
    "    young_pos_group = young_group[young_group['label'] == desired_label]\n",
    "    s_pos = len(young_pos_group)\n",
    "\n",
    "    aged_group = dataset[dataset[sensitive_column] != sensitive_value]\n",
    "    s_hat = len(aged_group)\n",
    "    aged_pos_group = aged_group[aged_group['label'] == desired_label]\n",
    "    s_hat_pos = len(aged_pos_group)\n",
    "    swaps_required = round(( (s * s_hat_pos) - (s_hat * s_pos) ) / (s + s_hat))\n",
    "\n",
    "    for i in range(int(swaps_required)):\n",
    "        row_cp = candidates_for_promotion.iloc[[i]]\n",
    "        row_cp['label'] = 1\n",
    "        candidates_for_promotion.iloc[[i]] = row_cp\n",
    "\n",
    "        row_cd = candidates_for_demotion.iloc[[i]]\n",
    "        row_cd['label'] = 2\n",
    "        candidates_for_demotion.iloc[[i]] = row_cd\n",
    "\n",
    "    # print(f'{swaps_required} swaps were required to reduce the bias in the dataset')\n",
    "    \n",
    "    new_dataset = pd.concat([rest_of_dataset, candidates_for_promotion, candidates_for_demotion])\n",
    "    return new_dataset\n",
    "\n",
    "data_cnd = CND(training_data, 0, 'A13', 1)"
   ]
  },
  {
   "source": [
    "I now split the dataset produced by the CND algorithm into features and labels, ready to train a new classifier.\n",
    "I also test the discrimination in the new dataset."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "The level of discrimination in the dataset produced by the CND algorithm is  0.00281\nThe KCDM of the unedited dataset was 0.1292\nThe % decrease of the KCDM through the CND is 97.82608695652175\n"
     ]
    }
   ],
   "source": [
    "X_train_cnd = data_cnd.iloc[:, :24] # columns 0 to 24\n",
    "Y_train_cnd = data_cnd.iloc[:, 24] # column 25\n",
    "\n",
    "original_KCDM = test_discrimination(training_data, 0, \"A13\", 1)\n",
    "KCDM = test_discrimination(data_cnd, 0, 'A13', 1)\n",
    "\n",
    "print('The level of discrimination in the dataset produced by the CND algorithm is ', round(KCDM, 5))\n",
    "print(f'The KCDM of the unedited dataset was {round(original_KCDM,5)}')\n",
    "print(f'The % decrease of the KCDM through the CND is {100*(1-KCDM/original_KCDM)}')"
   ]
  },
  {
   "source": [
    "I now train a new, unbiased model using the dataset produced by the CND algorithm"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "GaussianNB(priors=None, var_smoothing=1e-09)"
      ]
     },
     "metadata": {},
     "execution_count": 20
    }
   ],
   "source": [
    "nb_cnd = GaussianNB()\n",
    "nb_cnd.fit(X_train_cnd, Y_train_cnd)"
   ]
  },
  {
   "source": [
    "## 3.4.3 Evaluation and comparison"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Evaluating the original (biased) classifier:\nAccuracy: 0.686\nDisparate impact of classifier: 0.4015925480769231\nClassification report:\n              precision    recall  f1-score   support\n\n        Good       0.84      0.68      0.75       350\n         Bad       0.48      0.70      0.57       150\n\n   micro avg       0.69      0.69      0.69       500\n   macro avg       0.66      0.69      0.66       500\nweighted avg       0.73      0.69      0.70       500\n\nConfusion matrix:\n[[238 112]\n [ 45 105]]\n\n\nEvaluating the CND-trained classifier:\nAccuracy: 0.69\nDisparate impact of classifier: 0.7761834319526627\nClassification report:\n              precision    recall  f1-score   support\n\n        Good       0.81      0.73      0.77       350\n         Bad       0.49      0.61      0.54       150\n\n   micro avg       0.69      0.69      0.69       500\n   macro avg       0.65      0.67      0.65       500\nweighted avg       0.71      0.69      0.70       500\n\nConfusion matrix:\n[[254  96]\n [ 59  91]]\n"
     ]
    }
   ],
   "source": [
    "print('Evaluating the original (biased) classifier:')\n",
    "evaluate(nb_classifier, X_test, y_test)\n",
    "\n",
    "print('\\n\\nEvaluating the CND-trained classifier:')\n",
    "evaluate(nb_cnd, X_test, y_test)"
   ]
  },
  {
   "source": [
    "## Compare the performance on minority and majority groups"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "nb_classifier accuracy on the underprivileged group:  0.5385\nnb_classifier accuracy on the privileged group:  0.7247\nnb_cnd accuracy on the underprivileged group:  0.6346\nnb_cnd accuracy on the privileged group:  0.7045\n"
     ]
    }
   ],
   "source": [
    "test_set = pd.concat([X_test, y_test], axis=1)\n",
    "\n",
    "test_underprivileged = test_set[test_set['A13'] == 0]\n",
    "test_privileged = test_set[test_set['A13'] != 0]\n",
    "\n",
    "X_test_up = test_underprivileged.iloc[:, :24]\n",
    "y_test_up = test_underprivileged.iloc[:, 24]\n",
    "\n",
    "X_test_p = test_privileged.iloc[:, :24]\n",
    "y_test_p = test_privileged.iloc[:, 24]\n",
    "\n",
    "names = ['nb_classifier', 'nb_cnd']\n",
    "classifiers = [nb_classifier, nb_cnd]\n",
    "for i in range(2):\n",
    "    predictions_up = classifiers[i].predict(X_test_up)\n",
    "    predictions_p = classifiers[i].predict(X_test_p)\n",
    "\n",
    "    accuracy_up = metrics.accuracy_score(y_test_up, predictions_up)\n",
    "    accuracy_p = metrics.accuracy_score(y_test_p, predictions_p)\n",
    "\n",
    "    print(names[i], 'accuracy on the underprivileged group: ', round(accuracy_up, 4))\n",
    "    print(names[i], 'accuracy on the privileged group: ', round(accuracy_p, 4))"
   ]
  }
 ]
}