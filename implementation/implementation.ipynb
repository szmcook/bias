{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python36964bit1fe2bb4cf81446c4930ef0f70b991c44",
   "display_name": "Python 3.6.9 64-bit"
  },
  "metadata": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# Classical Implementation\n",
    "In this notebook I have trained a classical (and likely biased) machine learning model on the original dataset"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "Useful information for reference:\n",
    "\n",
    "number of instances: 1000 (190 young and 810 aged)\n",
    "\n",
    "labels: 1 is good, 2 is bad\n",
    "\n",
    "A13 == 0 means the individual is young"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## 0.1 Read in the data and export it as a CSV"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "with open('../german-credit-dataset/german.data-numeric', 'r') as infile:\n",
    "    data_contents = infile.read()    \n",
    "    data_contents = re.sub(r'[ ]+', \",\", data_contents)\n",
    "    data_contents = re.sub(r'^,', \"\", data_contents)\n",
    "    data_contents = re.sub(r'\\n,', \"\\n\", data_contents)\n",
    "    data_contents = re.sub(r',\\n', \"\\n\", data_contents)\n",
    "    # data_contents = re.sub(r'^,|\\n,|,\\n', \"\\n\", data_contents)\n",
    "\n",
    "    with open('../german-credit-dataset/german-numeric.csv', 'w') as outfile:\n",
    "        outfile.write(data_contents)"
   ]
  },
  {
   "source": [
    "## 0.2 Create a pandas dataframe holding the dataset\n",
    "\n",
    "The two most important data structures in this notebook are the original dataset, created below, and the modified dataset that's created in Task 4 (Fair implementation).\n",
    "\n",
    "The original dataset will be split into training and testing data, the training data will be used to create a modified (fair) dataset later whilst the testing data will not be used except for evaluating models trained on either the original training data or the fair training data."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "data read in and column names applied\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# data = pd.read_csv('../german-credit-dataset/german.csv')\n",
    "data = pd.read_csv('../german-credit-dataset/german-numeric.csv', header=None)\n",
    "data.columns = [\n",
    "    'A1',\n",
    "    'A2',\n",
    "    'A3',\n",
    "    'A5*',\n",
    "    'A6',\n",
    "    'A7',\n",
    "    'A9',\n",
    "    'A11',\n",
    "    'A12',\n",
    "    'A13',\n",
    "    'A14',\n",
    "    'A16',\n",
    "    'A18',\n",
    "    'A19',\n",
    "    'A20',\n",
    "    'A4????',\n",
    "    'A8',\n",
    "    'A10a',\n",
    "    'A10b',\n",
    "    'A15a',\n",
    "    'A15b',\n",
    "    'A17a',\n",
    "    'A17b',\n",
    "    'A17c',\n",
    "    'label'\n",
    "]\n",
    "\n",
    "\n",
    "print('data read in and column names applied')"
   ]
  },
  {
   "source": [
    "## 0.3 Encode the age data as Young (0) and Aged (1)"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.loc[data.A13 <= 25, \"A13\"] = 0\n",
    "data.loc[data.A13 > 25, \"A13\"] = 1"
   ]
  },
  {
   "source": [
    "## 3.3.2 Split the data into Features and labels and into training and testing"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "features = data.iloc[:, :24] # columns 0 to 24\n",
    "labels = data.iloc[:, 24] # column 25\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, labels, test_size=0.3, random_state=0) # This also shuffles the data\n",
    "\n",
    "# print(features.head)\n",
    "\n",
    "# print(labels.head)"
   ]
  },
  {
   "source": [
    "## 3.3.3a Train a Naive Bayes model"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "GaussianNB(priors=None, var_smoothing=1e-09)"
      ]
     },
     "metadata": {},
     "execution_count": 98
    }
   ],
   "source": [
    "# Import and fit a naive bayes model\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "nb_classifier = GaussianNB()\n",
    "nb_classifier.fit(X_train, y_train)"
   ]
  },
  {
   "source": [
    "## 3.3.3b Evaluate the model"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "\n",
    "def evaluate(trained_model, X_test, y_test):\n",
    "    predictions = trained_model.predict(X_test)\n",
    "    print(f'Accuracy: {metrics.accuracy_score(y_test, predictions)}\\n')\n",
    "    print('Classification report:')\n",
    "    print(metrics.classification_report(y_test, predictions, target_names=['Good','Bad'])[:166])\n",
    "    print('Confusion matrix:')\n",
    "    print(metrics.confusion_matrix(y_test, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Accuracy: 0.7266666666666667\n\nClassification report:\n              precision    recall  f1-score   support\n\n        Good       0.85      0.75      0.80       214\n         Bad       0.52      0.67      0.59        86\n\n  \nConfusion matrix:\n[[160  54]\n [ 28  58]]\n"
     ]
    }
   ],
   "source": [
    "evaluate(nb_classifier, X_test, y_test)"
   ]
  },
  {
   "source": [
    "## 3.3.4 Subsample a new dataset and retrain the model"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Accuracy: 0.38666666666666666\n\nClassification report:\n              precision    recall  f1-score   support\n\n        Good       0.77      0.13      0.23       203\n         Bad       0.34      0.92      0.49        97\n\n  \nConfusion matrix:\n[[ 27 176]\n [  8  89]]\n"
     ]
    }
   ],
   "source": [
    "# the aged group has 810 entries, 590 have the positive class\n",
    "# the young group has 190 entries, 110 have the positive class\n",
    "\n",
    "# sampled data should have 95 young +, young -, old +, old -?\n",
    "\n",
    "young_group = data[data['A13'] <= 25]\n",
    "young_pos_group = young_group[young_group['label'] == 1]\n",
    "young_neg_group = young_group[young_group['label'] == 2]\n",
    "\n",
    "aged_group = data[data['A13'] > 25]\n",
    "aged_pos_group = aged_group[aged_group['label'] == 1]\n",
    "aged_neg_group = aged_group[aged_group['label'] == 2]\n",
    "\n",
    "data_resampled = pd.concat([young_pos_group, young_neg_group, aged_pos_group, aged_neg_group])\n",
    "\n",
    "# TODO check that the index gets redone\n",
    "\n",
    "features_new = data_resampled.iloc[:, :24] # columns 0 to 19\n",
    "labels_new = data_resampled.iloc[:, 24] # column 20\n",
    "\n",
    "# print(features_new.head)\n",
    "# print(labels_new.head)\n",
    "\n",
    "\n",
    "X_train_new, X_test_new, y_train_new, y_test_new = train_test_split(features_new, labels_new, test_size=0.3, random_state=0) # This also shuffles the data\n",
    "\n",
    "nb_classifier_resampled_dataset = GaussianNB()\n",
    "nb_classifier_resampled_dataset.fit(X_train_new, y_train_new)\n",
    "evaluate(nb_classifier_resampled_dataset, X_test_new, y_test_new)\n",
    "\n",
    " # The accuracy is now terrible."
   ]
  },
  {
   "source": [
    "# Fairness adjustment"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## 3.4.0 Discrimination Measure\n",
    "We use the KCDM measure to test the Discrimination level present within the dataset."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "0.14944769330734242\n"
     ]
    }
   ],
   "source": [
    "def test_discrimination(data):\n",
    "    young_group = data[data['A13'] == 0]\n",
    "    young_pos_group = young_group[young_group['label'] == 1]\n",
    "    aged_group = data[data['A13'] == 1]\n",
    "    aged_pos_group = aged_group[aged_group['label'] == 1]\n",
    "\n",
    "    # print(young_group.shape[0])\n",
    "    # print(young_pos_group.shape[0])\n",
    "    # print(aged_group.shape[0])\n",
    "    # print(aged_pos_group.shape[0])\n",
    "\n",
    "    discrimination = aged_pos_group.shape[0] / aged_group.shape[0] - young_pos_group.shape[0] / young_group.shape[0]\n",
    "    return discrimination\n",
    "\n",
    "print(test_discrimination(data))\n"
   ]
  },
  {
   "source": [
    "## Apply the CND algorithm"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "The first step is to create a new dataset which is a concatenation of X_train and y_train, this will be modified to become unbiased"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "     A1  A2  A3  A5*  A6  A7  A9  A11  A12  A13  ...  A4????  A8  A10a  A10b  \\\n105   2  24   4  119   1   3   3    3    3    1  ...       0   0     0     1   \n68    4  36   2   18   1   3   3    4    4    1  ...       0   0     1     0   \n479   1  15   4   15   1   5   3    4    3    1  ...       0   0     1     0   \n399   4  24   4   15   4   3   2    1    1    1  ...       0   0     1     0   \n434   1   9   2   21   1   3   3    2    1    0  ...       0   0     1     0   \n..   ..  ..  ..  ...  ..  ..  ..  ...  ...  ...  ...     ...  ..   ...   ...   \n835   1  12   0   11   1   3   3    4    3    1  ...       1   0     1     0   \n192   2  27   2   39   1   3   3    2    3    1  ...       0   0     1     0   \n629   4   9   2   38   5   5   3    4    1    1  ...       0   0     1     0   \n559   2  18   4   19   1   2   3    2    1    1  ...       0   0     1     0   \n684   2  36   3   99   2   4   3    3    2    1  ...       0   0     1     0   \n\n     A15a  A15b  A17a  A17b  A17c  label  \n105     0     1     0     0     0      2  \n68      0     0     0     0     1      2  \n479     0     1     0     0     1      1  \n399     0     1     0     1     0      1  \n434     0     1     0     0     1      1  \n..    ...   ...   ...   ...   ...    ...  \n835     0     1     0     0     1      2  \n192     0     1     0     0     1      2  \n629     0     1     0     1     0      1  \n559     0     1     0     1     0      2  \n684     0     1     0     1     0      1  \n\n[700 rows x 25 columns]\n"
     ]
    }
   ],
   "source": [
    "new_dataset = pd.concat((X_train, y_train), axis=1)\n",
    "\n",
    "print(new_dataset)"
   ]
  },
  {
   "source": [
    "We want to add a list of label probabilities to this using the pre-built classifier"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rank(dataset, sensitive_value, sensitive_column, desired_label):\n",
    "    features = dataset.iloc[:, :24] # columns 0 to 24\n",
    "    labels = dataset.iloc[:, 24] # column 25\n",
    "\n",
    "    nb_classifier2 = GaussianNB()\n",
    "    nb_classifier2.fit(features, labels)\n",
    "\n",
    "    def nb_predict(row):\n",
    "        '''\n",
    "        INPUT: A row from the feature data\n",
    "        RETURNS: The probability of that row belonging to the positive class\n",
    "        '''\n",
    "        a = row.values\n",
    "        a = a.reshape(1,-1)\n",
    "        ps = nb_classifier2.predict_proba(a)\n",
    "        return ps[0][0]\n",
    "\n",
    "    # Calculate the probabilities R[x] for x in D and store them in a new column\n",
    "    new_dataset['rank_score'] = features.apply(nb_predict, axis=1, result_type='expand')\n",
    "    new_dataset['label'] = labels\n",
    "    # We also add indices for reference\n",
    "    # new_dataset['new_index'] = range(len(new_dataset))\n",
    "\n",
    "    candidates_for_promotion = new_dataset[new_dataset[sensitive_column] == sensitive_value][new_dataset['label'] != desired_label]\n",
    "    print(candidates_for_promotion.shape)\n",
    "    candidates_for_promotion.sort_values('rank_score', inplace=True, ascending=False) # FIXME if it doesn't work swap the ascending value\n",
    "    \n",
    "    candidates_for_demotion = new_dataset[new_dataset[sensitive_column] != sensitive_value][new_dataset['label'] == desired_label]\n",
    "    print(candidates_for_demotion.shape)\n",
    "    candidates_for_demotion.sort_values('rank_score', inplace=True, ascending=True) # FIXME if it doesn't work swap the ascending value\n",
    "\n",
    "    return candidates_for_promotion, candidates_for_demotion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(131, 26)\n",
      "(0, 26)\n",
      "/home/sam/.local/lib/python3.6/site-packages/ipykernel_launcher.py:24: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "/home/sam/.local/lib/python3.6/site-packages/ipykernel_launcher.py:28: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(     A1  A2  A3  A5*  A6  A7  A9  A11  A12  A13  ...  A8  A10a  A10b  A15a  \\\n",
       " 613   1  24   1   36   1   3   2    4    3    0  ...   1     0     0     1   \n",
       " 930   1  24   2   17   1   2   3    1    2    0  ...   0     0     1     0   \n",
       " 280   4  15   4   34   4   5   3    4    4    0  ...   1     1     0     1   \n",
       " 258   4  15   2   38   2   2   2    4    3    0  ...   1     1     0     0   \n",
       " 476   4  39   2   26   3   3   3    4    3    0  ...   1     1     0     0   \n",
       " ..   ..  ..  ..  ...  ..  ..  ..  ...  ...  ...  ...  ..   ...   ...   ...   \n",
       " 63    2  48   0  144   1   3   3    2    3    0  ...   0     1     0     0   \n",
       " 887   2  48   2  157   1   3   3    2    3    0  ...   0     1     0     0   \n",
       " 633   4   9   2   20   1   2   2    2    3    0  ...   0     0     1     1   \n",
       " 618   2  30   2   34   2   3   2    4    3    0  ...   0     0     1     1   \n",
       " 59    1  36   4   62   1   2   2    4    4    0  ...   0     0     1     1   \n",
       " \n",
       "      A15b  A17a  A17b  A17c  label    rank_score  \n",
       " 613     0     0     0     1      1  1.000000e+00  \n",
       " 930     1     0     1     0      1  9.999990e-01  \n",
       " 280     0     0     0     1      1  9.996803e-01  \n",
       " 258     1     0     0     1      1  9.995873e-01  \n",
       " 476     1     0     0     1      1  9.992980e-01  \n",
       " ..    ...   ...   ...   ...    ...           ...  \n",
       " 63      1     0     0     1      2  3.362609e-05  \n",
       " 887     1     0     0     1      2  2.794771e-05  \n",
       " 633     0     0     0     1      2  2.672182e-05  \n",
       " 618     0     0     0     1      2  2.845263e-06  \n",
       " 59      0     0     1     0      2  6.176174e-07  \n",
       " \n",
       " [131 rows x 26 columns],\n",
       " Empty DataFrame\n",
       " Columns: [A1, A2, A3, A5*, A6, A7, A9, A11, A12, A13, A14, A16, A18, A19, A20, A4????, A8, A10a, A10b, A15a, A15b, A17a, A17b, A17c, label, rank_score]\n",
       " Index: []\n",
       " \n",
       " [0 rows x 26 columns])"
      ]
     },
     "metadata": {},
     "execution_count": 108
    }
   ],
   "source": [
    "rank(new_dataset, 0, 'A13', '1')"
   ]
  },
  {
   "source": [
    "Now we want to identify two groups, CP and CD\n",
    "We then want to swap the labels of the corresponding rows in the new_dataset"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "NameError",
     "evalue": "name 'candidates_for_promotion' is not defined",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-106-5242c1618888>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcandidates_for_promotion\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcandidates_for_demotion\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# Sort the groups by their rank_score\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mcandidates_for_promotion\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msort_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'rank_score'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'candidates_for_promotion' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "print(len(candidates_for_promotion))\n",
    "print(len(candidates_for_demotion))\n",
    "\n",
    "# Sort the groups by their rank_score\n",
    "candidates_for_promotion.sort_values('rank_score', inplace=True)\n",
    "candidates_for_promotion.sort_values('rank_score', inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/home/sam/.local/lib/python3.6/site-packages/pandas/core/generic.py:5170: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  self[name] = value\n"
     ]
    }
   ],
   "source": [
    "# Calculate how many swaps we need\n",
    "young_group = data[data['A13'] == 0]\n",
    "young_group_good = young_group[young_group['Score'] == 1]\n",
    "aged_group = data[data['A13'] == 1]\n",
    "aged_group_good = aged_group[aged_group['Score'] == 1]\n",
    "\n",
    "swaps_required = ( (young_group.shape[0] * aged_group_good.shape[0]) - (aged_group.shape[0] * young_group_good.shape[0]) ) / (young_group.shape[0] + aged_group.shape[0])\n",
    "\n",
    "cp_indices = list(candidates_for_promotion['new_index'])\n",
    "cd_indices = list(candidates_for_demotion['new_index'])\n",
    "\n",
    "# Make that many swaps\n",
    "for i in range(1, int(swaps_required)):\n",
    "    i_cp = cp_indices[i]\n",
    "    new_dataset.iloc[i_cp].Score = 1\n",
    "    i_cd = cd_indices[i]\n",
    "    new_dataset.iloc[i_cd].Score = 2\n",
    "\n",
    "# Drop the columns we created\n",
    "new_dataset.drop(columns=['new_index', 'rank_score'])\n",
    "X_train = new_dataset.iloc[:, :24] # columns 0 to 24\n",
    "y_train = new_dataset.iloc[:, 24] # last column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "131\n79\n569\n407\n0.11223654731080368\n"
     ]
    }
   ],
   "source": [
    "# Retest the discrimination of this dataset\n",
    "print(test_discrimination(new_dataset))"
   ]
  },
  {
   "source": [
    "Train a new, unbiased model"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "GaussianNB(priors=None, var_smoothing=1e-09)"
      ]
     },
     "metadata": {},
     "execution_count": 14
    }
   ],
   "source": [
    "# Import and fit a naive bayes model\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "nb_classifier = GaussianNB()\n",
    "nb_classifier.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_predictions = nb_classifier.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Accuracy of the Naive Bayes classifier 0.7266666666666667\n\nClassification report for Naive Bayes (0:died, 1:recovered):\n              precision    recall  f1-score   support\n\n        Good       0.85      0.75      0.80       214\n         Bad       0.52      0.67      0.59        86\n\n  \n"
     ]
    }
   ],
   "source": [
    "print(f'Accuracy of the Naive Bayes classifier {metrics.accuracy_score(y_test, nb_predictions)}\\n')\n",
    "\n",
    "print(f'Classification report for Naive Bayes (0:died, 1:recovered):')\n",
    "print(metrics.classification_report(y_test, nb_predictions, target_names=['Good','Bad'])[:166])"
   ]
  },
  {
   "source": [
    "# Evaluation and comparison"
   ],
   "cell_type": "markdown",
   "metadata": {}
  }
 ]
}