{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python36964bit1fe2bb4cf81446c4930ef0f70b991c44",
   "display_name": "Python 3.6.9 64-bit"
  },
  "metadata": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# 2 Analysis"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "A11    68\nA12    62\nA14    50\nA13    10\nName: Status of existing checking account, dtype: int64\n12    37\n24    34\n18    24\n15    17\n9     13\n36    11\n6     10\n30     9\n48     8\n10     4\n45     3\n21     3\n60     3\n39     2\n27     2\n13     2\n8      1\n72     1\n20     1\n11     1\n14     1\n22     1\n33     1\n4      1\nName: Duration in month, dtype: int64\nA32    137\nA34     33\nA31      8\nA33      7\nA30      5\nName: Credit history, dtype: int64\nA43    64\nA42    52\nA40    32\nA41    14\nA49    10\nA46     7\nA45     6\nA44     4\nA48     1\nName: Purpose, dtype: int64\n1258     2\n1275     2\n2039     2\n433      2\n3913     1\n        ..\n5152     1\n932      1\n674      1\n11560    1\n1282     1\nName: Credit amount, Length: 186, dtype: int64\nA61    123\nA65     28\nA62     22\nA63     11\nA64      6\nName: Savings account/bonds, dtype: int64\nA73    78\nA72    54\nA74    36\nA75    13\nA71     9\nName: Present employment since, dtype: int64\n4    82\n2    48\n1    33\n3    27\nName: Installment rate in percentage of disposable income, dtype: int64\nA92    105\nA93     56\nA94     27\nA91      2\nName: Personal status and sex, dtype: int64\nA101    170\nA103     11\nA102      9\nName: Other debtors / guarantors, dtype: int64\n4    84\n2    59\n1    30\n3    17\nName: Present residence since, dtype: int64\nA123    71\nA121    60\nA122    47\nA124    12\nName: Property, dtype: int64\n23    48\n24    44\n25    41\n22    27\n21    14\n20    14\n19     2\nName: Age in years, dtype: int64\nA143    161\nA141     20\nA142      9\nName: Other installment plans, dtype: int64\nA152    106\nA151     79\nA153      5\nName: Housing, dtype: int64\n1    145\n2     44\n3      1\nName: Number of existing credits at this bank, dtype: int64\nA173    138\nA172     42\nA174      5\nA171      5\nName: Job, dtype: int64\n1    184\n2      6\nName: Number of people being liable to provide maintenance for, dtype: int64\nA191    145\nA192     45\nName: Telephone, dtype: int64\nA201    187\nA202      3\nName: foreign worker, dtype: int64\n1    110\n2     80\nName: label, dtype: int64\n20.96786155747837\n144.53856980259212\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "with open('../german-credit-dataset/german.data', 'r') as infile:\n",
    "    data_contents = infile.read()    \n",
    "    data_contents = re.sub(r' ', \",\", data_contents)\n",
    "\n",
    "    with open('../german-credit-dataset/german.csv', 'w') as outfile:\n",
    "        outfile.write(data_contents)\n",
    "\n",
    "data = pd.read_csv('../german-credit-dataset/german.csv')\n",
    "\n",
    "data.columns = [\n",
    "    'Status of existing checking account', \n",
    "    'Duration in month',\n",
    "    'Credit history',\n",
    "    'Purpose',\n",
    "    'Credit amount',\n",
    "    'Savings account/bonds',\n",
    "    'Present employment since',\n",
    "    'Installment rate in percentage of disposable income',\n",
    "    'Personal status and sex',\n",
    "    'Other debtors / guarantors',\n",
    "    'Present residence since',\n",
    "    'Property',\n",
    "    'Age in years',\n",
    "    'Other installment plans',\n",
    "    'Housing',\n",
    "    'Number of existing credits at this bank',\n",
    "    'Job',\n",
    "    'Number of people being liable to provide maintenance for',\n",
    "    'Telephone',\n",
    "    'foreign worker',\n",
    "    'label']\n",
    "# FIXME The labels overwrite the first row.\n",
    "# print(data.iloc[0])\n",
    "\n",
    "young_group = data[data['Age in years'] <= 25]\n",
    "aged_group = data[data['Age in years'] > 25]\n",
    "\n",
    "for i in range(21):\n",
    "    print(young_group.iloc[:, i].value_counts())\n",
    "\n",
    "g = 'Duration in month'\n",
    "print(aged_group[g].mean())\n",
    "print(aged_group[g].var())"
   ]
  },
  {
   "source": [
    "# 3 Implementation\n",
    "The implementation section this notebook is divided into 3 separate sections\n",
    "- Sections 0.x refer to the reading in and tidying up of the dataset\n",
    "- Sections 3.3.x refer to the implementation of a classical (and likely biased) machine learning model using the original dataset\n",
    "- Sections 3.4.x refer to the implementation of my chosen technique to reduce bias"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "Useful information for reference:\n",
    "\n",
    "number of instances: 1000 (190 young and 810 aged)\n",
    "\n",
    "labels: 1 is good, 2 is bad\n",
    "\n",
    "A13 == 0 means the individual is young"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## 0.1 Read in the data and export it as a CSV"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "with open('../german-credit-dataset/german.data-numeric', 'r') as infile:\n",
    "    data_contents = infile.read()    \n",
    "    data_contents = re.sub(r'[ ]+', \",\", data_contents)\n",
    "    data_contents = re.sub(r'^,', \"\", data_contents)\n",
    "    data_contents = re.sub(r'\\n,', \"\\n\", data_contents)\n",
    "    data_contents = re.sub(r',\\n', \"\\n\", data_contents)\n",
    "    # data_contents = re.sub(r'^,|\\n,|,\\n', \"\\n\", data_contents)\n",
    "\n",
    "    with open('../german-credit-dataset/german-numeric.csv', 'w') as outfile:\n",
    "        outfile.write(data_contents)"
   ]
  },
  {
   "source": [
    "## 0.2 Create a pandas dataframe holding the dataset\n",
    "\n",
    "The two most important data structures in this notebook are the original dataset, created below, and the modified dataset that's created in Task 4 (Fair implementation).\n",
    "\n",
    "The original dataset will be split into training and testing data, the training data will be used to create a modified (fair) dataset later whilst the testing data will not be used except for evaluating models trained on either the original training data or the fair training data."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "data read in and column names applied\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# data = pd.read_csv('../german-credit-dataset/german.csv')\n",
    "data = pd.read_csv('../german-credit-dataset/german-numeric.csv', header=None)\n",
    "data.columns = [\n",
    "    'A1',\n",
    "    'A2',\n",
    "    'A3',\n",
    "    'A5*',\n",
    "    'A6',\n",
    "    'A7',\n",
    "    'A9',\n",
    "    'A11',\n",
    "    'A12',\n",
    "    'A13',\n",
    "    'A14',\n",
    "    'A16',\n",
    "    'A18',\n",
    "    'A19',\n",
    "    'A20',\n",
    "    'A4????',\n",
    "    'A8',\n",
    "    'A10a',\n",
    "    'A10b',\n",
    "    'A15a',\n",
    "    'A15b',\n",
    "    'A17a',\n",
    "    'A17b',\n",
    "    'A17c',\n",
    "    'label'\n",
    "]\n",
    "\n",
    "\n",
    "print('data read in and column names applied')"
   ]
  },
  {
   "source": [
    "## 0.3 Encode the age data as Young (0) and Aged (1)"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.loc[data.A13 <= 25, \"A13\"] = 0\n",
    "data.loc[data.A13 > 25, \"A13\"] = 1"
   ]
  },
  {
   "source": [
    "## 3.3.2 Split the data into Features and labels and into training and testing"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "features = data.iloc[:, :24] # columns 0 to 24\n",
    "labels = data.iloc[:, 24] # column 25\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, labels, test_size=0.5, random_state=0) # This also shuffles the data\n",
    "\n",
    "# print(features.head)\n",
    "# print(labels.head)"
   ]
  },
  {
   "source": [
    "## 3.3.3a Train a Naive Bayes model\n",
    "Here I train the classicla Naive Bayes model using the original dataset."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "GaussianNB(priors=None, var_smoothing=1e-09)"
      ]
     },
     "metadata": {},
     "execution_count": 103
    }
   ],
   "source": [
    "# Import and fit a naive bayes model\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "nb_classifier = GaussianNB()\n",
    "nb_classifier.fit(X_train, y_train)"
   ]
  },
  {
   "source": [
    "## 3.3.3b Evaluate the model\n",
    "To evaluate this model I want to consider the accuracy of its predictions and the score it receives for disparate impact.\n",
    "I also chose to print out the confusion matrix and classification report."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We also want to measure the disparate impact of a model\n",
    "def disparate_impact(trained_model, sensitive_value, sensitive_column, desired_label, X_test, y_test):\n",
    "    data_test = pd.concat([X_test, y_test], axis=1)\n",
    "\n",
    "    data_test_unprivileged = data_test[data_test[sensitive_column] == sensitive_value]\n",
    "    data_test_privileged = data_test[data_test[sensitive_column] != sensitive_value]\n",
    "\n",
    "    # measure the rate of good outcomes among the unprivileged applicants\n",
    "    X_test_up = data_test_unprivileged.iloc[:, :24] \n",
    "    predictions_up = trained_model.predict(X_test_up)\n",
    "    good_up = (predictions_up == 1).sum()/len(predictions_up)\n",
    "\n",
    "    X_test_p = data_test_privileged.iloc[:, :24] \n",
    "    predictions_p = trained_model.predict(X_test_p)\n",
    "    good_p = (predictions_p == 1).sum()/len(predictions_p)\n",
    "\n",
    "    return good_up/good_p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "\n",
    "def evaluate(trained_model, X_test, y_test):\n",
    "    predictions = trained_model.predict(X_test)\n",
    "    print(f'Accuracy: {metrics.accuracy_score(y_test, predictions)}')\n",
    "    print(f'Disparate impact of classifier: {disparate_impact(trained_model, 0, \"A13\", 1, X_test, y_test)}')\n",
    "    print('Classification report:')\n",
    "    print(metrics.classification_report(y_test, predictions, target_names=['Good','Bad']))\n",
    "    print('Confusion matrix:')\n",
    "    print(metrics.confusion_matrix(y_test, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Accuracy: 0.686\nDisparate impact of classifier: 0.4015925480769231\nClassification report:\n              precision    recall  f1-score   support\n\n        Good       0.84      0.68      0.75       350\n         Bad       0.48      0.70      0.57       150\n\n   micro avg       0.69      0.69      0.69       500\n   macro avg       0.66      0.69      0.66       500\nweighted avg       0.73      0.69      0.70       500\n\nConfusion matrix:\n[[238 112]\n [ 45 105]]\n"
     ]
    }
   ],
   "source": [
    "evaluate(nb_classifier, X_test, y_test)"
   ]
  },
  {
   "source": [
    "## 3.3.4 Subsample a new dataset and retrain the model"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Accuracy: 0.675\nDisparate impact of classifier: 1.0368532955350815\nClassification report:\n              precision    recall  f1-score   support\n\n        Good       0.72      0.62      0.67        84\n         Bad       0.64      0.74      0.68        76\n\n   micro avg       0.68      0.68      0.68       160\n   macro avg       0.68      0.68      0.67       160\nweighted avg       0.68      0.68      0.67       160\n\nConfusion matrix:\n[[52 32]\n [20 56]]\n"
     ]
    }
   ],
   "source": [
    "# the aged group has 810 entries, 590 have the positive class\n",
    "# the young group has 190 entries, 110 have the positive class\n",
    "\n",
    "# sampled data should have 80 young +, young -, old +, old -?\n",
    "\n",
    "def resample(dataset):\n",
    "    young_group = dataset[dataset['A13'] == 0]\n",
    "\n",
    "    young_pos_group = young_group[young_group['label'] == 1]\n",
    "    young_pos_sample = young_pos_group.sample(n=80, random_state=0)\n",
    "\n",
    "    young_neg_group = young_group[young_group['label'] == 2]\n",
    "    young_neg_sample = young_neg_group.sample(n=80, random_state=0)\n",
    "\n",
    "    aged_group = dataset[dataset['A13'] == 1]\n",
    "\n",
    "    aged_pos_group = aged_group[aged_group['label'] == 1]\n",
    "    aged_pos_sample = aged_pos_group.sample(n=80, random_state=0)\n",
    "\n",
    "    aged_neg_group = aged_group[aged_group['label'] == 2]\n",
    "    aged_neg_sample = aged_neg_group.sample(n=80, random_state=0)\n",
    "\n",
    "    data_resampled = pd.concat([young_pos_sample, young_neg_sample, aged_pos_sample, aged_neg_sample])\n",
    "    return data_resampled\n",
    "\n",
    "# Resample the dataset\n",
    "data_resampled = resample(data)\n",
    "\n",
    "# Split the resampled dataset into training and testing data\n",
    "features_resampled = data_resampled.iloc[:, :24]\n",
    "labels_resampled = data_resampled.iloc[:, 24]\n",
    "X_train_resampled, X_test_resampled, y_train_resampled, y_test_resampled = train_test_split(features_resampled, labels_resampled, test_size=0.5, random_state=0) # This also shuffles the data\n",
    "\n",
    "# Train a Naive Bayes classifier on the resampled dataset\n",
    "nb_resampled = GaussianNB()\n",
    "nb_resampled.fit(X_train_resampled, y_train_resampled)\n",
    "evaluate(nb_resampled, X_test_resampled, y_test_resampled)\n",
    "\n",
    "# Measure the disparate impack of the classifier trained on the resampled dataset\n",
    "# disparate_impact(nb_resampled, 0, 'A13', 1, X_test_resampled, y_test_resampled)"
   ]
  },
  {
   "source": [
    "# Fairness adjustment"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## 3.4.0 Discrimination Measure\n",
    "We use the KCDM measure to test the Discrimination level present within the dataset."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "0.14944769330734242\n0.0\n"
     ]
    }
   ],
   "source": [
    "def test_discrimination(dataset, sensitive_value, sensitive_column, desired_class):\n",
    "    young_group = dataset[dataset[sensitive_column] == sensitive_value]\n",
    "    young_pos_group = young_group[young_group['label'] == desired_class]\n",
    "    aged_group = dataset[dataset[sensitive_column] != sensitive_value]\n",
    "    aged_pos_group = aged_group[aged_group['label'] == desired_class]\n",
    "\n",
    "    # print(young_group.shape[0])\n",
    "    # print(young_pos_group.shape[0])\n",
    "    # print(aged_group.shape[0])\n",
    "    # print(aged_pos_group.shape[0])\n",
    "\n",
    "    discrimination = aged_pos_group.shape[0] / aged_group.shape[0] - young_pos_group.shape[0] / young_group.shape[0]\n",
    "    return discrimination\n",
    "\n",
    "print(test_discrimination(data, 0, 'A13', 1))\n",
    "print(test_discrimination(data_resampled, 0, 'A13', 1))\n"
   ]
  },
  {
   "source": [
    "## 3.4.1 Apply the CND algorithm\n",
    "In this section I apply the CND algorithm to the training data from above. This yields an unbiased classifier which is then evaluated and compared with the original classifier."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "The first step is to combine X_train and y_train, this is the dataset which I will modify to become unbiased.\n",
    "I also test its level of discrimination using the function defined above."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.12919896640826867"
      ]
     },
     "metadata": {},
     "execution_count": 109
    }
   ],
   "source": [
    "training_data = pd.concat((X_train, y_train), axis=1)\n",
    "# print(new_dataset.head)\n",
    "\n",
    "test_discrimination(training_data, 0, 'A13', 1)"
   ]
  },
  {
   "source": [
    "I use the rank() function to return a set of candidates for promotion, a set of candidates for demotion and the rest of the dataset (which should remain untouched)"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rank(dataset, sensitive_value, sensitive_column, desired_label):\n",
    "    # Train a classifier using all the data available\n",
    "    features = dataset.iloc[:, :24] # columns 0 to 24\n",
    "    labels = dataset.iloc[:, 24] # column 25\n",
    "\n",
    "    nb_classifier2 = GaussianNB()\n",
    "    nb_classifier2.fit(features, labels)\n",
    "\n",
    "    def nb_predict(row):\n",
    "        '''\n",
    "        INPUT: A row from the feature data\n",
    "        RETURNS: The probability of that row belonging to the positive class\n",
    "        '''\n",
    "        a = row.values\n",
    "        a = a.reshape(1,-1)\n",
    "        ps = nb_classifier2.predict_proba(a)\n",
    "        return ps[0][0]\n",
    "\n",
    "    # Calculate the probabilities R[x] for x in D and store them in a new column\n",
    "    dataset['rank_score'] = features.apply(nb_predict, axis=1, result_type='expand')\n",
    "    dataset['label'] = labels\n",
    "\n",
    "    candidates_for_promotion = dataset[dataset[sensitive_column] == sensitive_value][dataset['label'] != desired_label]\n",
    "    # print(candidates_for_promotion.shape)\n",
    "    candidates_for_promotion.sort_values('rank_score', inplace=True, ascending=False)\n",
    "    \n",
    "    candidates_for_demotion = dataset[dataset[sensitive_column] != sensitive_value][dataset['label'] == desired_label]\n",
    "    # print(candidates_for_demotion.shape)\n",
    "    candidates_for_demotion.sort_values('rank_score', inplace=True, ascending=True)\n",
    "\n",
    "    rest_of_dataset_1 = dataset[dataset[sensitive_column] == sensitive_value][dataset['label'] == desired_label]\n",
    "    rest_of_dataset_2 = dataset[dataset[sensitive_column] != sensitive_value][dataset['label'] != desired_label]\n",
    "    rest_of_dataset = pd.concat([rest_of_dataset_1, rest_of_dataset_2])\n",
    "\n",
    "    return candidates_for_promotion, candidates_for_demotion, rest_of_dataset"
   ]
  },
  {
   "source": [
    "Here I implement the CND algorithm which takes a dataset and the relevant information and returns a dataset with KCDM=0."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/home/sam/.local/lib/python3.6/site-packages/ipykernel_launcher.py:23: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n/home/sam/.local/lib/python3.6/site-packages/ipykernel_launcher.py:27: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n/home/sam/.local/lib/python3.6/site-packages/ipykernel_launcher.py:31: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n/home/sam/.local/lib/python3.6/site-packages/ipykernel_launcher.py:32: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n/home/sam/.local/lib/python3.6/site-packages/ipykernel_launcher.py:19: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n/home/sam/.local/lib/python3.6/site-packages/ipykernel_launcher.py:23: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    }
   ],
   "source": [
    "def CND(dataset, sensitive_value, sensitive_column, desired_label):\n",
    "\n",
    "    candidates_for_promotion, candidates_for_demotion, rest_of_dataset = rank(dataset, sensitive_value, sensitive_column, desired_label)\n",
    "    \n",
    "    # Calculate how many swaps we need\n",
    "    young_group = dataset[dataset[sensitive_column] == sensitive_value]\n",
    "    s = len(young_group)\n",
    "    young_pos_group = young_group[young_group['label'] == desired_label]\n",
    "    s_pos = len(young_pos_group)\n",
    "\n",
    "    aged_group = dataset[dataset[sensitive_column] != sensitive_value]\n",
    "    s_hat = len(aged_group)\n",
    "    aged_pos_group = aged_group[aged_group['label'] == desired_label]\n",
    "    s_hat_pos = len(aged_pos_group)\n",
    "    swaps_required = round(( (s * s_hat_pos) - (s_hat * s_pos) ) / (s + s_hat))\n",
    "\n",
    "    for i in range(int(swaps_required)):\n",
    "        row_cp = candidates_for_promotion.iloc[[i]]\n",
    "        row_cp['label'] = 1\n",
    "        candidates_for_promotion.iloc[[i]] = row_cp\n",
    "\n",
    "        row_cd = candidates_for_demotion.iloc[[i]]\n",
    "        row_cd['label'] = 2\n",
    "        candidates_for_demotion.iloc[[i]] = row_cd\n",
    "\n",
    "    # print(f'{swaps_required} swaps were required to reduce the bias in the dataset')\n",
    "    \n",
    "    new_dataset = pd.concat([rest_of_dataset, candidates_for_promotion, candidates_for_demotion])\n",
    "    return new_dataset\n",
    "\n",
    "data_cnd = CND(training_data, 0, 'A13', 1)"
   ]
  },
  {
   "source": [
    "I now split the dataset produced by the CND algorithm into features and labels, ready to train a new classifier.\n",
    "I also test the discrimination in the new dataset."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "The level of discrimination in the dataset produced by the CND algorithm is  0.00281\nThe KCDM of the unedited dataset was 0.1292\nThe % decrease of the KCDM through the CND is 97.82608695652175\n"
     ]
    }
   ],
   "source": [
    "X_train_cnd = data_cnd.iloc[:, :24] # columns 0 to 24\n",
    "Y_train_cnd = data_cnd.iloc[:, 24] # column 25\n",
    "\n",
    "original_KCDM = test_discrimination(training_data, 0, \"A13\", 1)\n",
    "KCDM = test_discrimination(data_cnd, 0, 'A13', 1)\n",
    "\n",
    "print('The level of discrimination in the dataset produced by the CND algorithm is ', round(KCDM, 5))\n",
    "print(f'The KCDM of the unedited dataset was {round(original_KCDM,5)}')\n",
    "print(f'The % decrease of the KCDM through the CND is {100*(1-KCDM/original_KCDM)}')"
   ]
  },
  {
   "source": [
    "I now train a new, unbiased model using the dataset produced by the CND algorithm"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "GaussianNB(priors=None, var_smoothing=1e-09)"
      ]
     },
     "metadata": {},
     "execution_count": 113
    }
   ],
   "source": [
    "nb_cnd = GaussianNB()\n",
    "nb_cnd.fit(X_train_cnd, Y_train_cnd)"
   ]
  },
  {
   "source": [
    "## 3.4.3 Evaluation and comparison"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Evaluating the original (biased) classifier:\nAccuracy: 0.686\nDisparate impact of classifier: 0.4015925480769231\nClassification report:\n              precision    recall  f1-score   support\n\n        Good       0.84      0.68      0.75       350\n         Bad       0.48      0.70      0.57       150\n\n   micro avg       0.69      0.69      0.69       500\n   macro avg       0.66      0.69      0.66       500\nweighted avg       0.73      0.69      0.70       500\n\nConfusion matrix:\n[[238 112]\n [ 45 105]]\n\n\nEvaluating the CND-trained classifier:\nAccuracy: 0.69\nDisparate impact of classifier: 0.7761834319526627\nClassification report:\n              precision    recall  f1-score   support\n\n        Good       0.81      0.73      0.77       350\n         Bad       0.49      0.61      0.54       150\n\n   micro avg       0.69      0.69      0.69       500\n   macro avg       0.65      0.67      0.65       500\nweighted avg       0.71      0.69      0.70       500\n\nConfusion matrix:\n[[254  96]\n [ 59  91]]\n"
     ]
    }
   ],
   "source": [
    "print('Evaluating the original (biased) classifier:')\n",
    "evaluate(nb_classifier, X_test, y_test)\n",
    "\n",
    "print('\\n\\nEvaluating the CND-trained classifier:')\n",
    "evaluate(nb_cnd, X_test, y_test)"
   ]
  },
  {
   "source": [
    "## Compare the performance on minority and majority groups"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "nb_classifier accuracy on the underprivileged group:  0.5384615384615384\nnb_classifier accuracy on the privileged group:  0.7247474747474747\nnb_cnd accuracy on the underprivileged group:  0.6346153846153846\nnb_cnd accuracy on the privileged group:  0.7045454545454546\n"
     ]
    }
   ],
   "source": [
    "test_set = pd.concat([X_test, y_test], axis=1)\n",
    "\n",
    "test_underprivileged = test_set[test_set['A13'] == 0]\n",
    "test_privileged = test_set[test_set['A13'] != 0]\n",
    "\n",
    "X_test_up = test_underprivileged.iloc[:, :24]\n",
    "y_test_up = test_underprivileged.iloc[:, 24]\n",
    "\n",
    "X_test_p = test_privileged.iloc[:, :24]\n",
    "y_test_p = test_privileged.iloc[:, 24]\n",
    "\n",
    "names = ['nb_classifier', 'nb_cnd']\n",
    "classifiers = [nb_classifier, nb_cnd]\n",
    "for i in range(2):\n",
    "    predictions_up = classifiers[i].predict(X_test_up)\n",
    "    predictions_p = classifiers[i].predict(X_test_p)\n",
    "\n",
    "    accuracy_up = metrics.accuracy_score(y_test_up, predictions_up)\n",
    "    accuracy_p = metrics.accuracy_score(y_test_p, predictions_p)\n",
    "\n",
    "    print(names[i], 'accuracy on the underprivileged group: ', accuracy_up)\n",
    "    print(names[i], 'accuracy on the privileged group: ', accuracy_p)"
   ]
  }
 ]
}